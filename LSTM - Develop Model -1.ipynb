{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kütüphanelerin Yüklenmesi\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sys\n",
    "# Keras and LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Txt Dosyasının Açılması\n",
    "myfile = open(\"nirvananota.txt\",\"r\")\n",
    "data = myfile.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Em', 'G', 'Em', 'G', 'Em', 'G', 'Em', 'G', 'Em', 'G']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boşlukların temizlenmesi bütün notaların tek tek eleman olarak alınması\n",
    "clean = []\n",
    "for i in range(0,len(data)):\n",
    "    clean = clean + [x for x in data[i].split(\" \") if str(x) != '']\n",
    "    \n",
    "    \n",
    "clean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Karakterler için Dictionary Oluşturulması\n",
    "chars = sorted(list(set(clean)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'A#': 1,\n",
       " 'A#7': 2,\n",
       " 'A7': 3,\n",
       " 'Ab': 4,\n",
       " 'Am': 5,\n",
       " 'B': 6,\n",
       " 'B7': 7,\n",
       " 'Bm7': 8,\n",
       " 'C': 9,\n",
       " 'C#': 10,\n",
       " 'C#7': 11,\n",
       " 'C#m': 12,\n",
       " 'C7': 13,\n",
       " 'D': 14,\n",
       " 'D#7': 15,\n",
       " 'D7': 16,\n",
       " 'Dm': 17,\n",
       " 'Dm#': 18,\n",
       " 'E': 19,\n",
       " 'E7': 20,\n",
       " 'Em': 21,\n",
       " 'EmC': 22,\n",
       " 'F': 23,\n",
       " 'F#': 24,\n",
       " 'F#7': 25,\n",
       " 'F#m': 26,\n",
       " 'F7': 27,\n",
       " 'G': 28,\n",
       " 'G#': 29,\n",
       " 'G#7': 30,\n",
       " 'G#m': 31,\n",
       " 'G#m,': 32,\n",
       " 'G7': 33,\n",
       " 'new': 34,\n",
       " 'sleep': 35}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  2569\n",
      "Total Vocab:  36\n"
     ]
    }
   ],
   "source": [
    "# Toplam Nota ve Karakter Sayımız\n",
    "n_chars = len(clean)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  2559\n"
     ]
    }
   ],
   "source": [
    "# Notaların birbirlerine bağlanması örneğin ;\n",
    "# E7 G E C --> E7 G E TARGET/C\n",
    "seq_length = 10\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = clean[i:i + seq_length]\n",
    "\tseq_out = clean[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veriyi Modele Vermek İçin Hazırlıyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# Normalize Etmek.\n",
    "X = X / float(n_vocab)\n",
    "# Y değişkeni için One Hot Encoding Yapıyoruz.\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Yapısı 3 Layerli Stacked LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True,\n",
    "                input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(512, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(512))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bu kısımda modelin ağırlıklarını kaydetmek için şu şekilde bir metod uyguluyoruz ;\n",
    "\n",
    "- Eğer yeni epochta şu ana kadarki en düşük loss varsa onun ağırlıklarını kaydet yoksa devam et."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"stacked-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "2559/2559 [==============================] - 84s 33ms/step - loss: 3.2784\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.27843, saving model to stacked-weights-improvement-01-3.2784.hdf5\n",
      "Epoch 2/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 3.2096\n",
      "\n",
      "Epoch 00002: loss improved from 3.27843 to 3.20958, saving model to stacked-weights-improvement-02-3.2096.hdf5\n",
      "Epoch 3/100\n",
      "2559/2559 [==============================] - 78s 30ms/step - loss: 3.2259\n",
      "\n",
      "Epoch 00003: loss did not improve from 3.20958\n",
      "Epoch 4/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 3.1036\n",
      "\n",
      "Epoch 00004: loss improved from 3.20958 to 3.10363, saving model to stacked-weights-improvement-04-3.1036.hdf5\n",
      "Epoch 5/100\n",
      "2559/2559 [==============================] - 78s 30ms/step - loss: 2.9297\n",
      "\n",
      "Epoch 00005: loss improved from 3.10363 to 2.92973, saving model to stacked-weights-improvement-05-2.9297.hdf5\n",
      "Epoch 6/100\n",
      "2559/2559 [==============================] - 78s 31ms/step - loss: 2.5818\n",
      "\n",
      "Epoch 00006: loss improved from 2.92973 to 2.58183, saving model to stacked-weights-improvement-06-2.5818.hdf5\n",
      "Epoch 7/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 2.2848\n",
      "\n",
      "Epoch 00007: loss improved from 2.58183 to 2.28475, saving model to stacked-weights-improvement-07-2.2848.hdf5\n",
      "Epoch 8/100\n",
      "2559/2559 [==============================] - 78s 31ms/step - loss: 2.0192\n",
      "\n",
      "Epoch 00008: loss improved from 2.28475 to 2.01919, saving model to stacked-weights-improvement-08-2.0192.hdf5\n",
      "Epoch 9/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 1.7545\n",
      "\n",
      "Epoch 00009: loss improved from 2.01919 to 1.75448, saving model to stacked-weights-improvement-09-1.7545.hdf5\n",
      "Epoch 10/100\n",
      "2559/2559 [==============================] - 78s 31ms/step - loss: 1.5299\n",
      "\n",
      "Epoch 00010: loss improved from 1.75448 to 1.52992, saving model to stacked-weights-improvement-10-1.5299.hdf5\n",
      "Epoch 11/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 1.3365\n",
      "\n",
      "Epoch 00011: loss improved from 1.52992 to 1.33653, saving model to stacked-weights-improvement-11-1.3365.hdf5\n",
      "Epoch 12/100\n",
      "2559/2559 [==============================] - 78s 30ms/step - loss: 1.1785\n",
      "\n",
      "Epoch 00012: loss improved from 1.33653 to 1.17847, saving model to stacked-weights-improvement-12-1.1785.hdf5\n",
      "Epoch 13/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 1.0180\n",
      "\n",
      "Epoch 00013: loss improved from 1.17847 to 1.01798, saving model to stacked-weights-improvement-13-1.0180.hdf5\n",
      "Epoch 14/100\n",
      "2559/2559 [==============================] - 78s 31ms/step - loss: 0.9034\n",
      "\n",
      "Epoch 00014: loss improved from 1.01798 to 0.90342, saving model to stacked-weights-improvement-14-0.9034.hdf5\n",
      "Epoch 15/100\n",
      "2559/2559 [==============================] - 78s 31ms/step - loss: 0.7922\n",
      "\n",
      "Epoch 00015: loss improved from 0.90342 to 0.79217, saving model to stacked-weights-improvement-15-0.7922.hdf5\n",
      "Epoch 16/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.7703\n",
      "\n",
      "Epoch 00016: loss improved from 0.79217 to 0.77027, saving model to stacked-weights-improvement-16-0.7703.hdf5\n",
      "Epoch 17/100\n",
      "2559/2559 [==============================] - 78s 30ms/step - loss: 0.6608\n",
      "\n",
      "Epoch 00017: loss improved from 0.77027 to 0.66079, saving model to stacked-weights-improvement-17-0.6608.hdf5\n",
      "Epoch 18/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.6144\n",
      "\n",
      "Epoch 00018: loss improved from 0.66079 to 0.61438, saving model to stacked-weights-improvement-18-0.6144.hdf5\n",
      "Epoch 19/100\n",
      "2559/2559 [==============================] - 78s 31ms/step - loss: 0.5733\n",
      "\n",
      "Epoch 00019: loss improved from 0.61438 to 0.57333, saving model to stacked-weights-improvement-19-0.5733.hdf5\n",
      "Epoch 20/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.5736\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.57333\n",
      "Epoch 21/100\n",
      "2559/2559 [==============================] - 78s 30ms/step - loss: 0.5491\n",
      "\n",
      "Epoch 00021: loss improved from 0.57333 to 0.54910, saving model to stacked-weights-improvement-21-0.5491.hdf5\n",
      "Epoch 22/100\n",
      "2559/2559 [==============================] - 78s 31ms/step - loss: 0.5424\n",
      "\n",
      "Epoch 00022: loss improved from 0.54910 to 0.54245, saving model to stacked-weights-improvement-22-0.5424.hdf5\n",
      "Epoch 23/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.4952\n",
      "\n",
      "Epoch 00023: loss improved from 0.54245 to 0.49521, saving model to stacked-weights-improvement-23-0.4952.hdf5\n",
      "Epoch 24/100\n",
      "2559/2559 [==============================] - 78s 30ms/step - loss: 0.4461\n",
      "\n",
      "Epoch 00024: loss improved from 0.49521 to 0.44613, saving model to stacked-weights-improvement-24-0.4461.hdf5\n",
      "Epoch 25/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.4550\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.44613\n",
      "Epoch 26/100\n",
      "2559/2559 [==============================] - 78s 30ms/step - loss: 0.4477\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.44613\n",
      "Epoch 27/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.4401\n",
      "\n",
      "Epoch 00027: loss improved from 0.44613 to 0.44010, saving model to stacked-weights-improvement-27-0.4401.hdf5\n",
      "Epoch 28/100\n",
      "2559/2559 [==============================] - 78s 30ms/step - loss: 0.4115\n",
      "\n",
      "Epoch 00028: loss improved from 0.44010 to 0.41153, saving model to stacked-weights-improvement-28-0.4115.hdf5\n",
      "Epoch 29/100\n",
      "2559/2559 [==============================] - 78s 30ms/step - loss: 0.4187\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.41153\n",
      "Epoch 30/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.4817\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.41153\n",
      "Epoch 31/100\n",
      "2559/2559 [==============================] - 77s 30ms/step - loss: 0.4207\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.41153\n",
      "Epoch 32/100\n",
      "2559/2559 [==============================] - 76s 30ms/step - loss: 0.3986\n",
      "\n",
      "Epoch 00032: loss improved from 0.41153 to 0.39862, saving model to stacked-weights-improvement-32-0.3986.hdf5\n",
      "Epoch 33/100\n",
      "2559/2559 [==============================] - 77s 30ms/step - loss: 0.3616\n",
      "\n",
      "Epoch 00033: loss improved from 0.39862 to 0.36162, saving model to stacked-weights-improvement-33-0.3616.hdf5\n",
      "Epoch 34/100\n",
      "2559/2559 [==============================] - 78s 30ms/step - loss: 0.3734\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.36162\n",
      "Epoch 35/100\n",
      "2559/2559 [==============================] - 77s 30ms/step - loss: 0.3726\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.36162\n",
      "Epoch 36/100\n",
      "2559/2559 [==============================] - 78s 31ms/step - loss: 0.3515\n",
      "\n",
      "Epoch 00036: loss improved from 0.36162 to 0.35154, saving model to stacked-weights-improvement-36-0.3515.hdf5\n",
      "Epoch 37/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3908\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.35154\n",
      "Epoch 38/100\n",
      "2559/2559 [==============================] - 78s 31ms/step - loss: 0.3768\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.35154\n",
      "Epoch 39/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3415\n",
      "\n",
      "Epoch 00039: loss improved from 0.35154 to 0.34146, saving model to stacked-weights-improvement-39-0.3415.hdf5\n",
      "Epoch 40/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3960\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.34146\n",
      "Epoch 41/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3456\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.34146\n",
      "Epoch 42/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3890\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.34146\n",
      "Epoch 43/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3530\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.34146\n",
      "Epoch 44/100\n",
      "2559/2559 [==============================] - 78s 31ms/step - loss: 0.3327\n",
      "\n",
      "Epoch 00044: loss improved from 0.34146 to 0.33274, saving model to stacked-weights-improvement-44-0.3327.hdf5\n",
      "Epoch 45/100\n",
      "2559/2559 [==============================] - 78s 31ms/step - loss: 0.3444\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.33274\n",
      "Epoch 46/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3395\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.33274\n",
      "Epoch 47/100\n",
      "2559/2559 [==============================] - 78s 31ms/step - loss: 0.3282\n",
      "\n",
      "Epoch 00047: loss improved from 0.33274 to 0.32824, saving model to stacked-weights-improvement-47-0.3282.hdf5\n",
      "Epoch 48/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3380\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.32824\n",
      "Epoch 49/100\n",
      "2559/2559 [==============================] - 78s 31ms/step - loss: 0.3110\n",
      "\n",
      "Epoch 00049: loss improved from 0.32824 to 0.31103, saving model to stacked-weights-improvement-49-0.3110.hdf5\n",
      "Epoch 50/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3473\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.31103\n",
      "Epoch 51/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.3406\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.31103\n",
      "Epoch 52/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3030\n",
      "\n",
      "Epoch 00052: loss improved from 0.31103 to 0.30297, saving model to stacked-weights-improvement-52-0.3030.hdf5\n",
      "Epoch 53/100\n",
      "2559/2559 [==============================] - 78s 30ms/step - loss: 0.3110\n",
      "\n",
      "Epoch 00053: loss did not improve from 0.30297\n",
      "Epoch 54/100\n",
      "2559/2559 [==============================] - 78s 30ms/step - loss: 0.3237\n",
      "\n",
      "Epoch 00054: loss did not improve from 0.30297\n",
      "Epoch 55/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2948\n",
      "\n",
      "Epoch 00055: loss improved from 0.30297 to 0.29480, saving model to stacked-weights-improvement-55-0.2948.hdf5\n",
      "Epoch 56/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3376\n",
      "\n",
      "Epoch 00056: loss did not improve from 0.29480\n",
      "Epoch 57/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.3096\n",
      "\n",
      "Epoch 00057: loss did not improve from 0.29480\n",
      "Epoch 58/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3082\n",
      "\n",
      "Epoch 00058: loss did not improve from 0.29480\n",
      "Epoch 59/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.2781\n",
      "\n",
      "Epoch 00059: loss improved from 0.29480 to 0.27812, saving model to stacked-weights-improvement-59-0.2781.hdf5\n",
      "Epoch 60/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2792\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.27812\n",
      "Epoch 61/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3310\n",
      "\n",
      "Epoch 00061: loss did not improve from 0.27812\n",
      "Epoch 62/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.2771\n",
      "\n",
      "Epoch 00062: loss improved from 0.27812 to 0.27709, saving model to stacked-weights-improvement-62-0.2771.hdf5\n",
      "Epoch 63/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3126\n",
      "\n",
      "Epoch 00063: loss did not improve from 0.27709\n",
      "Epoch 64/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.2793\n",
      "\n",
      "Epoch 00064: loss did not improve from 0.27709\n",
      "Epoch 65/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3042\n",
      "\n",
      "Epoch 00065: loss did not improve from 0.27709\n",
      "Epoch 66/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.2635\n",
      "\n",
      "Epoch 00066: loss improved from 0.27709 to 0.26354, saving model to stacked-weights-improvement-66-0.2635.hdf5\n",
      "Epoch 67/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2954\n",
      "\n",
      "Epoch 00067: loss did not improve from 0.26354\n",
      "Epoch 68/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.2926\n",
      "\n",
      "Epoch 00068: loss did not improve from 0.26354\n",
      "Epoch 69/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3153\n",
      "\n",
      "Epoch 00069: loss did not improve from 0.26354\n",
      "Epoch 70/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2636\n",
      "\n",
      "Epoch 00070: loss did not improve from 0.26354\n",
      "Epoch 71/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.2764\n",
      "\n",
      "Epoch 00071: loss did not improve from 0.26354\n",
      "Epoch 72/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2918\n",
      "\n",
      "Epoch 00072: loss did not improve from 0.26354\n",
      "Epoch 73/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.3056\n",
      "\n",
      "Epoch 00073: loss did not improve from 0.26354\n",
      "Epoch 74/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2912\n",
      "\n",
      "Epoch 00074: loss did not improve from 0.26354\n",
      "Epoch 75/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.2728\n",
      "\n",
      "Epoch 00075: loss did not improve from 0.26354\n",
      "Epoch 76/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2656\n",
      "\n",
      "Epoch 00076: loss did not improve from 0.26354\n",
      "Epoch 77/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.3091\n",
      "\n",
      "Epoch 00077: loss did not improve from 0.26354\n",
      "Epoch 78/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.2572\n",
      "\n",
      "Epoch 00078: loss improved from 0.26354 to 0.25723, saving model to stacked-weights-improvement-78-0.2572.hdf5\n",
      "Epoch 79/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2671\n",
      "\n",
      "Epoch 00079: loss did not improve from 0.25723\n",
      "Epoch 80/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.2467\n",
      "\n",
      "Epoch 00080: loss improved from 0.25723 to 0.24666, saving model to stacked-weights-improvement-80-0.2467.hdf5\n",
      "Epoch 81/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2791\n",
      "\n",
      "Epoch 00081: loss did not improve from 0.24666\n",
      "Epoch 82/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.3162\n",
      "\n",
      "Epoch 00082: loss did not improve from 0.24666\n",
      "Epoch 83/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2800\n",
      "\n",
      "Epoch 00083: loss did not improve from 0.24666\n",
      "Epoch 84/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.3071\n",
      "\n",
      "Epoch 00084: loss did not improve from 0.24666\n",
      "Epoch 85/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2784\n",
      "\n",
      "Epoch 00085: loss did not improve from 0.24666\n",
      "Epoch 86/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2585\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.24666\n",
      "Epoch 87/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.2728\n",
      "\n",
      "Epoch 00087: loss did not improve from 0.24666\n",
      "Epoch 88/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2800\n",
      "\n",
      "Epoch 00088: loss did not improve from 0.24666\n",
      "Epoch 89/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2800\n",
      "\n",
      "Epoch 00089: loss did not improve from 0.24666\n",
      "Epoch 90/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2360\n",
      "\n",
      "Epoch 00090: loss improved from 0.24666 to 0.23598, saving model to stacked-weights-improvement-90-0.2360.hdf5\n",
      "Epoch 91/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.2485\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.23598\n",
      "Epoch 92/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2492\n",
      "\n",
      "Epoch 00092: loss did not improve from 0.23598\n",
      "Epoch 93/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.2560\n",
      "\n",
      "Epoch 00093: loss did not improve from 0.23598\n",
      "Epoch 94/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2528\n",
      "\n",
      "Epoch 00094: loss did not improve from 0.23598\n",
      "Epoch 95/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2544\n",
      "\n",
      "Epoch 00095: loss did not improve from 0.23598\n",
      "Epoch 96/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.2485\n",
      "\n",
      "Epoch 00096: loss did not improve from 0.23598\n",
      "Epoch 97/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2743\n",
      "\n",
      "Epoch 00097: loss did not improve from 0.23598\n",
      "Epoch 98/100\n",
      "2559/2559 [==============================] - 80s 31ms/step - loss: 0.2455\n",
      "\n",
      "Epoch 00098: loss did not improve from 0.23598\n",
      "Epoch 99/100\n",
      "2559/2559 [==============================] - 79s 31ms/step - loss: 0.2517\n",
      "\n",
      "Epoch 00099: loss did not improve from 0.23598\n",
      "Epoch 100/100\n",
      "2559/2559 [==============================] - 82s 32ms/step - loss: 0.2692\n",
      "\n",
      "Epoch 00100: loss did not improve from 0.23598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b9cacc7b8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100, batch_size=5, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelin en düşük loss'lu ağırlıklı halini çağırıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"stacked-weights-improvement-90-0.2360.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bu kısımda olay başlıyor. Yapılan olay şu, öncelikle başlangıç değerleri veriliyor bunlara göre predictionlar yapılarak sürekli yeni nota tahminleniyor ardından sürekli başlangıç değerleri silinerek devam ediliyor. \n",
    "\n",
    "### Örnek\n",
    "- D B7 D B7 A G F# sleep A F için bir nota tahmin edildi. Mesela buna **B7** diyelim. Ardından\n",
    "- B7 D B7 A G F# sleep A F B7 şeklinde verilip yeni tahmin alınıyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" E7E7EF#GEAGBB \"\n",
      "F# E7 sleep E7 A G B B F# E7 E7 A G B B F# E7 new E E A G B7 G E sleep E E A G B7 G E sleep E E A G B7 G E sleep E E A G B7 G E sleep E E A G B7 G E sleep E E A G B7 G E sleep E E A G B7 G E sleep E E A G B7 G E sleep E E A G B7 G E sleep E E A G B7 G E sleep E E A G B7 G E sleep E E A G B7 G E sleep E E A G B7 G E sleep E E A G B7 G E sleep E E A G B7 G E sleep E E A G B7 G E sleep E E A G \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "deneme = []\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(150):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result+str(\" \"))\n",
    "    pattern.append(index)\n",
    "    deneme.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "deneme = deneme[len(pattern):]\n",
    "print(\"\\nDone.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
